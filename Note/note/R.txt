https://blog.naver.com/spdlqjdudghl

https://beomy.tistory.com/43  - mvp 패턴

https://www.data.go.kr/


http://naver.me/xRCDOuSZ


# 함수
log(10) + 5 // 로그함수
sqrt(25) // 제곱근
max(5,3,2) // 가장큰 값
min()
abs(-10)
factorial(5)
sin(pi/2), cos(), tan()

# 유용한 함수들
** apply : 행렬이나 데이터 프레임을 행 단위로, 또는 열 단위로 행렬의 합이나 평균, 표준편차 등을 계산할 때 씀.
apply(no.patients,1,sum) // 여기서 1은 행을 의미, 2는 열. 1과 2로 행렬을 구분한다.
lapply(listPatients$no.patients, mean) // 데이터타입을 list로 리턴.
sapply(listPatients$no.patients, mean) // 데이터타입이 벡터. 평균내는 두가지 형태의 함수

** tapply : 벡터 등에 있는 데이터를 특정 기준으로 묶어 그룹마다 특정 함수 적용
tapply(weigth.furit,mean) // 과일을 기준으로 평균을 구해라.
tapply(iris$Sepal.Width, iris$Species, sum) // 종을 기준으로

# 원하는 정보 가져오기
IR.1 <- subset(iris, Species=="setosa")
IR.2 <- subset(iris, Sepal.Length>5.0 & Sepal.Width>4.0)
IR.2[, c(2,4)]

* 구분할 것.
iris["Species"] // 벡터, 매트릭스와 데이터프레임 모두 가능.
iris[,"Species"] // 데이터프레임, 데이터프레임만 가능. iris[,5]와 같다.
iris$Species // 벡터. 데이터프레임만 가능

/////////////////////////////////////////////////////////////////////////////////////////////////////////////
# 단축키
* ctrl + shift + enter // 전체실행

# library install 순서!
1. packages에서 다운받고
2. install.packages("ggplot2") // 설치한 패키지 불러오기
3. library(ggplot2) 		// install된거 메모리올리기
 
# 외부파일 읽어오기
* tips=read.csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv') 

# 통계내기
* summary(tips) // 요약 통계량
  str(tips) // 데이터 프레임에 저장된 데이터의 갯수, 변수, 자료형, 저장된 데이터의 일부를 보여줌.

# 데이터타입
숫자형 1, 2, 3, -4, 12.8
문자형 'TOM', "JANE"
논리형 TRUE, FALSE
특수값 null, na(missing value), NaN, Inf, -Int
* w <- c(1,2,3,"a","b","C") // 전부다 문자열로 바뀜

# 데이터 셋의 기본정보 확인.
dim(iris) 		// 행, 열을 파악할 때
nrow(iris)		// 행을 파악할 때
ncol(iris)		// 열을 파악할 때
colnames(iris)
head(iris)
tail(iris)
str(iris) 		// 데이터 분석
unique(iris[,5]) 	// 중복제거
table(iris[,"Species"]) 	// 품종의 종류별 개수 세기

# 표 그리기
* 벡터는 1차원 배열 데이터 ex) 몸무게 30, 32, 38
  매트리스, 데이터프레임은 2차원 배열 데이터 x, y로 row와 col로 구성
* v2 <- c(1,2,5, 50:90) // 1,2,5 찍고 50~90까지
* v3 <- seq(1,101,3) // 1부터 3씩 더하면서 101번까지 찍고 seq해라
* 2차원으로 바꾸기
  score <- c(90,85,60)
  names(score) <- c("A","B","C") // 열의 이름 정하기

# 그래프 실행
tips%>%ggplot(aes(size)) + geom_histogram()
tips%>%ggplot(aes(total_bill, tip)) + geom_point()
tips%>%ggplot(aes(total_bill, tip)) + geom_point(aes(col=day))
tips%>%ggplot(aes(total_bill, tip)) + geom_point(aes(col=day, pch=sex), size=3)

# 반복문
  v4 <- rep(1:5, times=3)
  v5 <-  rep(c(1,5,9), times=3)

# 배열
* v1[10] // 벡터값의 10번째방
* 배열 방으로 보는 방법
d <- c(1,4,3,7,8)
d[c(1,3,5)]
d[1:3]
d[seq(1,5,2)] 	// 방번호임.
d[-2]		// 2번째방 빼기
d[-c(3:5)]
* 정렬하기
sort(d, decreasing = TRUE)

# 리스트 : 서로 다른 자료형들의 값들을 1차원 배열에 저장하고 다룰 수 있다
  my.info <- list(name='Tom','Jerry', age=60, status=TRUE, score=ds)
  my.info[[5]]

# 팩터 : 문자형 데이터가 저장된 벡터의 일종. 성별이나 혈액형, 선호 정당 등과 같이 저장할 문자값들이 fix되어있을때 팩터를 사용. 레벨이 있음
* 팩터의 선언
bt <- c('A','B','C','O','AB','A')  // 만약에 여기다 E를 넣으면 오류남.
bt.new <-  factor(bt)
levels(bt.new)

# 매트릭스 : 2차원 데이터라고도 함.(1차원은 벡터) 키,몸무게,나이 등 여러 주제의 데이터. 벡터들의 모임이라 할 수 있다. *** 모든 셀의 데이터타입이 같다!
* 행은 관측값(observation), 열은 변수(variable)라고 함
* z <- matrix(1:20, nrow=4, ncol=5) // 1~20까지 열단위로 먼저 들어감.
** z2 <- matrix(1:20, nrow=4, ncol=5, byrow=T) // 행단위로 먼저 들어감.
* m1 <- cbind(x,y) // 바인드로 행 묶어버리기
** m2 <- rbind(x,y) // 바인드로 열 묶어버리기
* 행과 열 자리바꾸기
z <- matrix(1:20, nrow=4, ncol=5)
t(z)
* 조회방법
z[2,4] // 조회방법
z[1:2,] // 1행과 2행만 다 나와라
z[,c(1,4)] // 1열과 4열만 다 나와라
z['a','i']
* 매트릭스 이름 정하기
rownames(z) <- c('a','b','c','d')
colnames(z) <- c('e','f','g','h','i')

# 데이터 프레임 : 자료형이 다른 컬럼으로 구성되어있다
* 데이터 프레임 만드는 방법
city <- c("seoul","tokyo","washington")
rank <- c(1,3,2)
city.info <- data.frame(city,rank)
city.info

## 매트릭스와 데이터 프레임에서 사용하는 함수.
colSums(iris[,-5]) 	// 열별 합계
colMeans(iris[,-5])	// 열별 평균
rowSums(iris[,-5])
* 매트릭스와 데이터프레임의 자료구조 확인
class(iris) // iris 데이터셋의 자류구조 확인
is.matrix(iris), is.data.frame(iris)
* 매트릭스와 데이터프레임의 자료구조 변환
st <- data.frame(state.x77)
iris.m <- as.matrix(iris[,1:4])

# 리스트 : 서로 다른 기본 데이터형을 갖는자료 구조를 포함함. 데이터 프레임보다 넓은 의미의 데이터 모임. 
            *** 데이터 프레임과 달리 모든 속성의 크기가 같을 필요가 없음
ds <- c(90,85,70,84)
my.info <- list(name='TOM',age=60, status=TRUE, score=ds) // 리스트 만드는 방법
my.info[[4]] = my.info[["score"]] = my.info$score

patients = data.frame(name=c("철수","춘향","길동"), age= c(22,20,25), gender = factor(c("M","F","M")), blood.type = factor(c("A","O","B")))
no.patients = data.frame(day=c(1:6), no=c(50,60,70,80,90,65))
listPatients = list(patients, no.patients)
listPatients = list(patients = patients, no.patients = no.patients) // 요소에 이름주기
listPatients$patients // 위의 이름으로 출력가능.
listPatients[[1]]
listPatients[["patients"]]



** 패키지와 함수 // RStudio에서 우측하단의 인스톨을 통하여 설치해야 함.
base 기본 패키지
readr 패키지
data.table 패키지
feather 패키지

** 파일 형식 변환 // 엑셀파일에 테이블 형태의 데이터가 저장된 상태에서 .csv형태로 변환하여 R에서 .csv파일을 읽음. 이 파일은 데이터 프레임 형태로 저장됨.
setwd("C:/source") // 여기 경로의 폴더에 존재하는 csv(Comma-Separated Values)파일 갖고오는 것.(setworkingdirectory의 약자)
air <- read.csv("airquality.csv", header=T) // csv파일 읽을때
head(air)
air <- read.table("airquality.txt", header=T) // txt파일 읽을때

* csv는 이런 파일임.
name,korean,english
조씨,60,60
김씨,70,70
이씨,80,50	
박씨,60,50	

* txt파일은 띄어쓰기로 구분
name korean english
조씨 60 60
김씨 70 70
이씨 80 50	
박씨 60 50

write.csv(listPatients, file="c://source/output.csv", quote=F)	 // csv파일로 저장
write.table(listPatients, file="c://source/output2.txt", quote=F) // 텍스트파일로 저장 quote=f는 따옴표가 없음.

setwd("C:/source")
my.iris <- subset(iris, Species='Setosa')
write.csv(my.iris, "my_iris.csv", row.names=F) // row.names=F는 행번호 붙이지 않을 때.



## 조건문
job.type <- 'A'
if(job.type == 'B'){
    bonus <- 200
} else { 
    bonus <- 100
}
print(bonus)

a <- 10
b <- 20
c <- ifelse(a>b, a,b) // 3항연산자. true면 a, false면 b

x=c(-5:5)
options(digits=3) // 숫자 표현 시 유효자릿수를 3자리로 설정
sqrt(x) // NaN이 포함되어있어서 오류발생! sqrt는 루트를 의미함.
sqrt(ifelse(x>=0, x, NA)) // 따라서 이렇게 해결해줘야 함.
## 반복문
for (반복변수 in 반복범위){
	반복할 명령문(들)
}

for(i in 1:5){
  print(i);
}

for(i in 1:9){
  cat('2*', i, '=', 2*i,'\n');
}	// 구구단의 2단 만들기

for(i in 1:20){
  if(i%%2==0){
    print(i)
  }
} 	// 짝수만 출력하기

* 강제로 값 바꾸기
x <- iris
x[1,2] <- NA; x[1,3] <- NA
x[2,3] <- NA; x[3,4] <- NA

# 데이터 프레임의 열별 결측값 확인
** for문을 이용한 방법
for(i in 1:ncol(x)){
  this.na <-  is.na(x[,i]) // na는 NaN. 그게 몇개가 있느냐
  cat(colnames(x)[i], "\t", sum(this.na), "\n")
}

** apply를 이용한 방법
col_na <-  function(y){
  return(sum(is.na(y)))
}
na_count <-  apply(x, 2, FUN=col_na)
na_count

# 데이터 프레임의 행별 결측값 확인
rowSums(is.na(x))
sum(rowSums(is.na(x))>0) // NaN이 포함된 행갯수
sum(is.na(x)) // NaN 총갯수

# 결측값을 제외하고 새로운 데이터셋 만들기
head(x)
x[!complete.cases(x),]
y <- x[!complete.cases(x),]
head(y)

# 특이값
  데이터를 파악할때 왜곡을 가져올 수 있으므로 분석할 때 특이값을 제외하는 경우가 많음. 불량제품이나 사기거래탐지할 때 유용.

st <- data.frame(state.x77)
boxplot(st$Income)
boxplot.stats(st$Income)$out // out은 특이값을 표현한다.


out.val <- boxplot.stats(st$Income)$out // 특이값 추출
st$Income[st$Income %in% out.val] <- NA // 특이값을 NA로 대체
head(st)
newdata <- st[complete.cases(st),] 	// NA가 포함된 행 제거
head(newdata)

# 데이터 정렬
1. 벡터의 정렬
v1 <- c(1,7,6,8,4,2,3)
order(v1)
v1 <- sort(v1)
v1
v2 <- sort(v1, decreasing=T)
v2

2. 매트릭스와 데이터 프레임의 정렬
order(iris$Sepal.Length)
iris[order(iris$Sepal.Length),]
iris.new <- iris[order(iris$Sepal.Length),]
head(iris.new)
iris[order(iris$Species, decreasing=T, iris$Petal.Length),]

# 데이터 분리와 선택
1. 데이터 분리
sp <- split(iris, iris$Species)
sp

2. 데이터 선택
subset(iris, Species =="setosa")
subset(iris, Sepal.Length > 7.5 & Sepal.Width >2.0)
subset(iris, Sepal.Length > 7.6, select=c(Petal.Length,Petal.Width))

# 데이터 샘플링 // 주어진 값들이 있을 때 그중에서 임의의 개수의 값들을 추출하는 작업. 데이터셋의 크기가 너무 커서 데이터 ㅜㄴ석에 시간이 많이 걸리는 경우
		   일부 데이터만 샘플링하여 대략의 결과를 미리 확인
* 복원 추출과 비복원 추출로 나뉨.

1. 행을 임의로 추출하기
idx <-  sample(1:nrow(iris), size=50, replace = FALSE)
iris.50 <-  iris[idx,]		// 50개의 행 추출
dim(iris.50)			// 행과 열의 개수 확인
head(iris.50)

2. set.seed() 함수 이해하기
sample(1:20, size=5)
set.seed(100) // 이것을 사용하면 random값이었던 sample이 고정값으로 바뀜

3. 데이터 조합
combn(1:5,3) // 1~5에서 3개를 뽑는 조합

x = c("red","green","blue","black","white")
com <- combn(x,2)
com	// x의 원소를 2개씩 봅는 조합
for(i in 1:ncol(com)) {
	cat(com[,i], "\n")
}	// 조합된 것을 출력

# 데이터 집계와 병합
1. 데이터 집계 // 2차원 데이터는 합계나 평균을 계산해야 하는 일이 많음. 이러한 작업을 집계라하며 aggregate()함수를 통해서 가능
agg <- aggregate(iris[,-5], by=list(iris$Species), FUN=mean) // iris[,-5] 집계작업을 수행할 대상, 아이리스트에서 ,-5 제외하고 by는 기준점을 잡아서 평균을 내라.
agg <- aggregate(iris[,-5], by=list(표준편차=iris$Species), FUN=sd)  // iris의 각 변수의 품종별 표준편차 출력
agg <- aggregate(mtcars, by=list(cyl=mtcars$cyl, vs=mtcars$vs), FUN=max) // 각 변수의 최대값 출력

2. 데이터 병합
* 병합(merge) : 분리된 데이터 파일을 공통 컬럼을 기준으로 하나로 합치는 작업
x <-  data.frame(name=c("a","b","C"), math=c(90,80,40))
y <- data.frame(name=c("a","b","d"), math=c(75,60,90))
z <-  merge(x,y, by=c("name"))

merge(x,y, all.x=T)
merge(x,y, all.y=T)
merge(x,y, all=T)

# 결측값 처리
is.na : NA인 데이터가 있으면 T, 없으면 F
na.omit : NA인 데이터를 제거. 즉, NA가 포함된 행을 지운다
함수의 속성을 이용 : na.rm=T로 하여 함수 수행 시 NA를 제외

table(is.na(airquality))

air_narm1=na.omit(airquality)
mean(air_narm1$Ozone) 

# 이상값 처리 // 이상한 데이터
patient=data.frame(name=c("환자1","환자2","환자3","환자4","환자5"), age=c(22, 20, 25, 30, 27), gender=factor(c("M","F","M","K","F")), blood.type=factor(c("A","O","B","AB","C")))
patient_outrm=patient[patient$gender=="M"|patient$gender=="F",] // K라는 이상값을 뽑아내기 위해서
patient_outrm

patient[!is.na(patient$gender)&!is.na(patient$blood.type),]// na가 아닌값들만 출력

boxplot(airquality[, c(1:4)]) 
boxplot(airquality[,1])$stats // Ozone의 boxplot 통계값 계산

# base R을 이용한 데이터 가공
* gapminder 라이브러리

# glimpse(gapminder)
gapminder[gapminder$country == "Croatia", "pop"]

# dplyr 라이브러리를 이용한 데이터 가공
* %>% 





@ 단일변수 자료의 탐색
# 자료의 종류
1. 범주형 자료(질적 자료)
* 기본적으로 숫자로 표현할 수 없고, 대소비교나 산술연산이 적용되지 않음. ex)성별, 혈액형, 선호색 등등
2. 연속형 자료(양적 자료)
* 크기가 있는 숫자로 구성, 대소 비교가 가능하고, 평균, 최댓값, 최소값과 같은 산술 연산이 가능.

# 단일변수, 다중변수
* 단일 변수자료는 벡터, 다중 변수자료는 매트릭스나 데이터 프레임에 저장하여 분석

table(favorite) 			// 도수분포표 계산. 열의 이름마다 갯수가 나타나게됨
table(favorite)/length(favorite) 	// 비율 출력

ds <- table(favorite) // 그래프 그릴때 table 작업이 선행되어야 하구나.
barplot(ds, main='favorite season') 	// 막대그래프 형. main은 이 표의 제목
pie(ds, main='favorite season')		// 원그래프 형

weight <- c(60,62,64,65,68,69)
median(weight) // 중앙값
mean(weight, trim=0.2) // 절사평균(상하위 20% 제외)

* 4분위수 : 앞에서부터 Q1, Q2(중앙값), Q3이라고 부름

mydata <- c(60,62,64,65,68,69,120)
quantile(mydata)
quantile(mydata, (0:10)/10) // 10% 단위로 구간을 나누어 계산
summary(mydata)

var(mydata)		// 분산		
sd(mydata)		// 표준편차
range(mydata)		// 값의 범위
diff(range(mydata)) 	// 최댓값, 최솟값의 차이

hist(dist,		// 히스토그램 : 연속형자료들의 시각화. 키같은것은 범위에 애매하기때문에 일정한 구간을 정해줌.
     main="Histogram for 제동거리",
     xlab = "제동거리",
     ylab = "빈도수",
     border= "red",
     col= "green",
     las= 2,
     breaks=5)

* 막대그래프 vs 히스토그램
1. 막대그래프는 막대끼리 떨어져있지만 히스토그램은 전부붙어있다.(구간이기 때문에!)
2. 막대그래프에서는 막대의 면적이 의미가 없지만 히스토그램에서는 막대의 면적도 의미가 있음.

dist <- cars[,2]
boxplot(dist, main="자동차 제동거리리")

boxplot.stats(dist)
$stats
[1]  2 26 36 56 93  		// 최소값,1사분위수,중앙값,3사분위수,최대값

$n
[1] 50				// 자료의 개수

$conf
[1] 29.29663 42.70337  		// 중앙값에 관련된 신뢰 구간

$out
[1] 120				// 특이값의 목록


boxplot(Petal.Length~Species, data=iris, main="품종별 꽃잎의 길이")


* 여러 그래프 그리기
par(mfrow=c(1,3)) 			// 그래프 3개 설정
barplot(table(mtcars$carb),
        main="barplot of Carburetors",
        xlab="#of carburetors",
        ylab="frequency",
        col="blue"
        )
barplot(table(mtcars$cyl),
        main= "barplot of Cylender",
        xlab="#of carburetors",
        ylab="frequency",
        col="red")
barplot(table(mtcars$gear),
        main="Barplot of Grar",
        xlab="#of carburetors",
        ylab="frequency",
        col="green")
par(mfrow=c(1,1))			// 다시 원위치

# 다중변수 자료(다변량 자료) : 변수가 2개 이상인 자료. 따라서 표현하려면 매트릭스나 데이터 프레임이 필요하다.
* 산점도란 2개의 변수로 구성된 자료의 분포를 알아보는 그래프
plot(wt, mpg, main = "중량-연비 그래프",
        xlab="중량",
        ylab="연비",
        col="red",
        pch=19)

vars <- c("mpg","disp", "drat", "wt")
vars
mpg
wt
target <-  mtcars[,vars]
head(target)
pairs(target, main="Multi Plots") // 단일그래프는 plot, 여러가지 그래프를 그릴땐 pairs. 만약에 1행 2열에 있는 그래프를 보자면 x축이 mpg, y축이 disp

iris.2 <- iris[,3:4]			// 데이터 준비
point <- as.numeric(iris$Species)	// 점의 모양
color <- c("red","green","blue")	// 점의 컬러
plot(iris.2,
        main="Iris plot",
        pch=c(point),
        col=color[point])


# 상관분석과 상관계수
* 강한 선형적 관계 : 점들이 밀집되어있어서 하나의 선처럼 보일때
beers = c(5,2,9,8,3,7,3,5,3,5)
bal <- c(0.1,0.03,0.19,0.12,0.04,0.0095,0.07,0.06,0.02,0.05)
tbl <- data.frame(beers,bal)	
tbl
plot(bal~beers,data=tbl) 	// 산점도
res <-  lm(bal~beers,data=tbl)	// 회귀식 도출
abline(res)			// 회귀선 그리기
cor(beers,bal)			// 상관계수 계산


month = 1:12
late = c(5,8,7,9,4,6,12,13,8,6,6,4)
plot(month,late,		// x와 y데이터
main="지각생통계",
type="l",			// 그래프의 종류 선택
lty=1,				// 선의 종류 선택
lwd=1,				// 선의 굵기 선택
xlab="Month",			// x축 레이블
ylab="Late cnt")		// y축 레이블

* 선그래프. 시계열 그래프라고함.
* 복수의 선그래프 작성
month = 1:12
late1 = c(5,8,7,9,4,6,12,13,8,6,6,4)
late2 = c(4,6,5,8,7,8,10,11,6,5,7,3)
plot(month,late1,
     main="Late Student",
     type="b",			// 그래프의 종류 
     lty=1,			// 선의 종류
     col="red",			// 선의 색
     xlab="Month",		
     ylab="Late cnt",
     ylim=c(1,15)		// y축 값의 (하한, 상한)
     )

* grp 변수추가
grp <- c()					// grp는 주택가격을 상중하로 분류. 25.0이상이면 상 17이면 하, 나머지 중으로 분류
for(i in 1:nrow(myds)){
        if(myds$medv[i] >= 25.0){
                grp[i] <- "H"
        } else if(myds$medv[i] <= 17.0){
                grp[i] <- "L"
        } else {
                grp[i] <- "M"
        }
        
}
str(grp)

grp <- factor(grp)
grp <- factor(grp, levels=c("H","M","L"))
grp
myds <- data.frame(myds, grp)
myds

* 여러그래프 비교
par(mfrow=c(2,3))
for(i in 1:5){
        hist(myds[,i], main=colnames(myds)[i], col="yellow")
}

myds

* 상자그림으로 비교
par(mfrow=c(2,3))
for(i in 1:5){
        boxplot(myds[,i], main=colnames(myds)[i])
}
par(mfrow=c(1,1)) // 가상화면 분할 이거 꼭해줄 것.

* 다중 산점도를 통한 변수간 상관 관계의 확인
pairs(myds[,-6])

* 그룹 정보를 포함한 변수 간 상관관계의 확인
point <- as.integer(myds$grp)			// 점의 모양 설정
color <- c("red","green","blue")		// 점의 색 지정
pairs(myds[,-6], pch=point, col=color[point])

* 다중 그래프 
height1 <- c(4,18,5,8)
height2 <- c(9,15,20,6)
height <- rbind(height1, height2)
height
name <- c("영업1팀","영업2팀","영업3팀","영업4팀")
legend_lbl <- c("2014년","2015년")

barplot(height, main="부서별 영업 실적",
        names.arg=name,
        xlab="부서", ylab="영업 실적(억원)",
        col=c("darkblue","red"),
        legend.text=legend_lbl,
        ylim=c(0,35)
        )
boxplot(mag, main="지진발생강도의 분포", xlab="지진강도", ylab="발생건수수", col="red")

* 트리맵
library(treemap)
treemap
data(GNI2014)
head(GNI2014)

treemap(GNI2014,
        index=c("continent","iso3"),	// 계층구조 설정
        vSize="population",		// 타일의 크기
        vColor="GNI",			// 타일의 컬러
        type="value",			// 타일 컬러링 방법
        bg.labels="yellow",		// 레이블의 배경색
        title="World's GNI")		// 트리맵 제목

st <- data.frame(state.x77)
symbols(st$Illiteracy, st$Murder,	
        circles=st$Population,		// 원의 반지름의 열
        inchec=0.3,			// 원의 크기 조절값
        fg="white",			// 원의 테두리 색
        bg="lightgray",			// 원의 바탕색
        lwd=1.5,			// 원의 테두리선 두께
        xlab="rate of Olliteracy",
        ylab="crime(murder) rate",
        main="illiteracy and Crime")

text(st$Illiteracy,st$Murder,		// 텍스트가 출력될 x,y좌표
     rownames(st),			// 출력할 텍스트
     cex=0.6,				// 폰트 크기
     col="brown")			// 폰트 컬러

* 모자이크플롯
head(mtcars)
mosaicplot(~gear+vs, data = mtcars, color=TRUE,
           main = "Gear and VS")

* ggplot 패키지
month <- c(1,2,3,4,5,6)						// 월을 표현
rain <- c(55,50,45,50,60,70)					// 강수량
df <- data.frame(month,rain)					// 그래프를 작성할 대상 데이터
ggplot(df, aes(x=month,y=rain))					// 그래프를 그릴 데이터 지정
geom_bar(stat="identity", width=0.7, fill="steelblue")		// 막대의 높이는 y축에 해당하는 열의 값, 막대의 폭과 색 지정.

* ggplot으로 히스토그램 그리기
ggplot(iris, aes(x=Petal.Length)) + geom_histogram(binwidth=0.5)


# 크롤링
* 남의 사이트에서 가져오는것. 스크래핑이라고도 한다.
1. rvest랑 stringr 다운받고 메모리 올리기
2. URL복사 : https://www.coupang.com/np/search?q=%EC%97%AC%EC%84%B1%ED%81%AC%EB%A1%9C%EC%8A%A4%EB%B0%B1&channel=user&component=&eventCategory=SRP&trcid=&traid=&sorter=scoreDesc&minPrice
=&maxPrice=&priceRange=&filterType=&listSize=36&filter=&isPriceRange=false&brand=&offerCondition=&rating=0&page=1 // 페이지까지만 사용!

3. reply_list <-  character() 				// 상품명
   reply_list2 <- numeric()				// 가격 

3. content <- read_html(mainURL) 			// 주소 읽어오기

4. node_1 <- html_nodes(content, ".name")		// 상품명
   node_2 <- html_nodes(content, ".price-value")	// 가격
	
5. reply1 <- html_text(node_1)				// DOM형식으로 받아오기
   reply2 <- html_text(node_2)  			
	
6. reply_list <- append(reply_list, reply1)		// node들 떼버리고 String만
   reply_list2 <- append(reply_list2, reply2)

7. df <- data.frame(reply_list, reply_list2)		// data.frame으로 만들기

8. colnames(df) = c("품명","가격")			// 열 이름 지정

9. setwd("c:/source")					// 파일로 만들기
   write.csv(df,"여성가방.csv",sep=",",row.names=FALSE)

10. View(df)						// 도표로 보기


1. 스크래핑 대상 URL 할당
2. 웹문서추출
3. 상품정보 추출
4. 데이터 정제
5. 데이터 프레임만들기
6. 데이터 정렬

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
mainURL <- "https://www.coupang.com/np/search?q=%EC%97%AC%EC%84%B1%ED%81%AC%EB%A1%9C%EC%8A%A4%EB%B0%B1&channel=user&component=&eventCategory=SRP&trcid=&traid=&sorter=scoreDesc&minPrice=&maxPrice=&priceRange=&filterType=&listSize=36&filter=&isPriceRange=false&brand=&offerCondition=&rating=0&page=1"
reply_list <-  character()
reply_list2 <- numeric()

content <- read_html(mainURL)
content       

node_1 <- html_nodes(content, ".name")
node_2 <- html_nodes(content, ".price-value")   

reply1 <- html_text(node_1)
reply2 <- html_text(node_2)                                                                                                                                                                                    

reply_list <- append(reply_list, reply1)
reply_list2 <- append(reply_list2, reply2)

df <- data.frame(reply_list, reply_list2)
View(df)

colnames(df) = c("품명","가격")

setwd("c:/source")
write.csv(df,"여성가방.csv",sep=",",row.names=FALSE)

View(df)
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
* for문으로 페이지 마다 따오기
for(pgCnt in 1:10){
  url <- paste0(mainURL, pgCnt)
  content <- read_html(url)
  
  node_1 <- html_nodes(content, ".name")
  node_2 <- html_nodes(content, ".price-value")   
  
  reply1 <- html_text(node_1)
  reply2 <- html_text(node_2)                                                                                                                                                                                    
  
  reply_list <- append(reply_list, reply1)
  reply_list2 <- append(reply_list2, reply2)
  df <- data.frame(reply_list, reply_list2)
  
  colnames(df) = c("품명","가격")
  
  setwd("c:/source")
  write.csv(df,"여성가방.csv",row.names=FALSE, sep=",")
}
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
# 회귀분석 : 회귀 이론을 기초로 독립변수가 종속변수에 미치는 영향을 파악하여 예측모델을 도출하는 통계적 방법
* 독립변수 : 주식시세에 영향을 미치는 요인들(매출액, 원유가격, 국제정세, 정부발표) 	// 설명변수
* 종속변수 : 독립변수의 영향에 따라 값이 결정되는 주식시세				// 반응변수
** 예측모델 or 예측모형 : 독립변수에 해당하는 자료와 종속변수에 해당하는 자료를 모아 관계를 분석하고 통계

* 단순선형 회귀식 : y = Wx + b(x는 독립변수, y는 종속변수, W,b는 상수) 
head(cars)
plot(dist~speed, data=cars)	// 산점도를 통해 선형 관계 확인

model <- lm(dist~speed, cars)	// 회귀모델 구하기
model

abline(model)			// 회귀선을 산점도에 표시
coef(model)[1]			// b 값 출력
coef(model)[2]			// W값출력

* 주행속도에 따른 제동거리 구하기
b <- coef(model)[1]
W <- coef(model)[2]

speed <- 30		// 주행속도
dist <- W*speed +b 
dist			// 제동거리

speed <- 35		// 주행속도
dist <- W*speed +b 
dist			// 제동거리

speed <- 40		// 주행속도
dist <- W*speed +b 
dist			// 제동거리






# 분석 대상 데이터 준비
setwd("C:/source")

library(ggplot2)
library(ggmap)
library(readxl)

files <- c("201512","201606","201612","201706","201712")
columns <- c("상가업소번호","상호명","상권업종대분류명","상권업종중분류명","상권업종소분류명","시군구명","행정동명","경도","위도")
ds.total <- NULL

for(i in 1:length(files)){
        filename <- paste("seoul_",files[i],".xlsx", sep="")
        cat("read ", filename, "...\n")			// 읽을 파일 이름 출력
        ds <- read_excel(filename)			// 엑셀 파일 읽기
        ds <- data.frame(ds)				// 데이터 프레임으로 변환
        ds <- ds[,columns]				// 분석에 필요한 변수만 추출
        ds$수집연월 <- rep(i, nrow(ds))			// 데이터 수집 시점
        ds.total <- rbind(ds.total,ds)			// 데이터 통합
}

head(ds.total)





str(ds.total)
unique(ds.total$수집연월)				// 수집연월
unique(ds.total$상권업종대분류명)			// 상권업종 대분류
unique(ds.total$상권업종중분류명)			// 상권업종 중분류
unique(ds.total$상권업종소분류명)			// 상권업종 소분류

sum(is.na(ds.total))					// NA포함여부 확인
ds.201712 <- subset(ds.total, ds.total$수집연월==5)	// 201712 수집데이터만 추출
dim(ds.201712)

store.level_1 <- aggregate(ds.201712[,1],		// 업종별 점포수(대분류)
                           by=list(대분류=ds.201712$상권업종대분류명),
                           FUN=length)


# 지도그리기

library(ggplot2)
library(ggmap)
library(readxl)

1. https://cloud.google.com/maps-platform/#get-started 들어가서 API활성화

AIzaSyAwn5jGa4t49FYjYk_IEAfx8VtJ9_szfp8 // 내 API Key

# API로 지도 받아오기
store.region <- data.frame(store.region, store.region.loc[,2:3])
register_google(key='AIzaSyAwn5jGa4t49FYjYk_IEAfx8VtJ9_szfp8')
cen <- c(mean(store.region$경도), mean(store.region$위도))
map <- get_googlemap(center=cen,					// 마커 없는 지도 가져오기
                     maptype="roadmap",
                     size=c(640,640),
                     zoom=11)
gmap <- ggmap(map)							// 지도를 저장
gmap + geom_point(data=store.region,
                  aes(x=경도,y=위도,size=count),
                  alpha=0.5, col="red") + 
        scale_size_continuous(range = c(1,15))+				// 원의 크기 조절
        geom_text(data=store.region,					// 지도 위에 텍스트 표시
                  aes(x=경도,y=위도),					// 텍스트 위치(=구의 좌표)
                  size=3,						// 텍스트 크기
                  lable=store.region$구이름)				// 텍스트 내용


# 점포수가 많은 상위 10개 동 확인
store.dong <- aggregate(ds.201712[,1],
                        by=list(동이름=ds.201712$행정동명),
                        FUN=length)
store.dong
names(store.dong)[2] = c("count")
store.dong <- store.dong[order(store.dong$count,decreasing=T),]
dong.top10 <- store.dong[1:10,]
dong.top10
ggplot(dong.top10, aes(x=reorder(동이름,-count),y=count))+
        geom_bar(stat="identity", width=0.7, fill="steelblue")+
        ggtitle("점포수 많은 상위 10개 동")+
        theme(plot.title = element_text(color="black", size=14, face="bold"),
              axix.text.x = element_text(angle = 45))

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

library(ggmap)
register_google(key='AIzaSyAwn5jGa4t49FYjYk_IEAfx8VtJ9_szfp8')
gc <- geocode(enc2utf8("종로구"))					// 지점의 경도 위도
gc
cen <- as.numeric(gc)							// 경도 위도를 숫자로
cen
map <- get_googlemap(center=cen)					// 지도 생성   center(중심의 좌표값 지정), zoom(3(대륙)~21(빌딩),size, maptype(terrain,roadmap,stellite,hybrid)
ggmap(map)								// 지도 화면에 보이기

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

library(ggmap)
register_google(key='AIzaSyAwn5jGa4t49FYjYk_IEAfx8VtJ9_szfp8')
gc <- geocode(enc2utf8("설악산"))
gc
cen <- as.numeric(gc)
cen
map <- get_googlemap(center=cen,
                     zoom=9,
                     size=c(640,640),
                     maptype="roadmap")
ggmap(map)

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

# 숫자로 지점 정하기
cen <- c(-118.233248, 34.085015)
map <- get_googlemap(center=cen)
ggmap(map)

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

# 마커로 위치 찍기
gc <- geocode(enc2utf8("용인"))
cen <- as.numeric(gc)
map <- get_googlemap(center=cen,
                     maptyp="roadmap",
                     marker=gc)

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

names <- c("용두암","성산일출봉","정방폭포","중문관광단지","한라산1100고지","차귀도")
addr <- c("제주시 용두암길 15",
          "서귀포시 성산읍 성산리",
          "서귀포시 동홍동 299-3",
          "서귀포시 중문동 2624-1",
          "서귀포시 색달동 산1-2",
          "제주시 한경면 고산리 125")
gc <- geocode(enc2utf8(addr))

df <- data.frame(name=names,
                 lon=gc$lon,
                 lat=gc$lat)
df
ggmap(map)

cen <- c(mean(df$lon),mean(df$lat))
map <- get_googlemap(center=cen,
                     maptype="roadmap",
                     zoom=10,
                     size=c(640,640),
                     marker=gc)
ggmap(map)

gmap <- ggmap(map)
gmap+geom_text(data=df, 		// 지도 위에 텍스트 표시
               aes(x=lon,y=lat),	// 텍스트 위치(관광지 좌표)
               size=5,			// 텍스트 크기
               label=df$name)		// 텍스트 내용

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
# 지도 위에 데이터 표시
sp <- sample(1:nrow(wind),50)
df <- wind[sp,]
head(df)

cen <- c(mean(df$lon), mean(df$lat))
gc <- data.frame(lon=df$lon, lat= df$lat)
head(gc)

# 측정 위치에 마커 표시하기
map <- get_googlemap(center=cen,
                     maptype="roadmap",
                     zoom=6,
                     marker=gc)
ggmap(map)

# 풍속을 원의 크기로 표시하기
map <- get_googlemap(center=cen,		// 마커 없는 지도 가져오기
                     maptype="roadmap",
                     zoom=6)
gmap <- ggmap(map)				// 지도를 저장
		gmap+geom_point(data=df,	// 풍속을 원의 크기로 표시
                aes(x=lon,y=lat,size=spd),
                alpha=0.5,
                col="blue") +
        scale_size_continuous(range = c(1,14))	// 원의 크기 조절

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
# 워드 클라우드
1. 텍스트 파일 혀태로 준비
2. 파일의 끝부분 처리를 반드시 줄 바꿈을 하고 저장
3. 파일을 저장할 때 [다른 이름으로 저장] 선택하고 인코딩을 'UTF-8'로 선택
4. 파일 이름이나 폴더 경로에 한글이 포함되어 있으면 파일을 읽을 때 에러가 발생하는 경우가 있으므로 영어로 저장 


Sys.setenv(JAVA_HOME='C:/Program Files/Java/jdk1.8.0_221')

library(wordcloud)			// 워드 클라우드
library(KoNLP)				// 한국어 처리
library(RColorBrewer)			// 색상 선택

setwd("C:/source")
text <- readLines("mis_document.txt", encoding="UTF-8")	// 파일 읽기
buildDictionary(ext_dic = "woorimalsam")		// 우리말씀 한글사전 로딩
pal2 <- brewer.pal(8, "Dark2")				// 팔레트 생성
noun <- sapply(text,extractNoun, USE.NAMES=F)		// 명사 추출
noun							// 추출된 명사 출력
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
noun2 <- unlist(noun)					// 추출된 명사 통합
wordcount <- table(noun2)				// 단어 빈도수 계산
temp <- sort(wordcount, decreasing=T)[1:10]		// 빈도수 높은 단어 10개 추출
temp
temp <- temp[-1]					// 공백 단어 제거
barplot(temp,						// 막대그래프 작성
        names.arg = names(temp),			// 막대 이름을 단어로 표시
        col = "lightblue",				// 막대의 색상 지정
        main = "빈도수 높은 단어", ylab = "단어 빈도수")


wordcloud(names(wordcount),		// 단어들
          freq=wordcount,		// 단어들의 빈도
          scale=c(6,0.7),		// 단어의 폰트 크기
          min.freq = 3,			// 단어의 최소 빈도
          random.order=F,		// 단어의 출력 위치
          rot.per=.1,			// 90도 회전 단어 비율
          colors=pal2)			// 단어의 색

# 빈도수 높은데 워드 클라우드에 없으면 사용자 사전에 추가
buildDictionary(ext_dic ="woorimalsam",				
                user_dic=data.frame("정치","ncn"),
                replace_usr_dic = T)

noun <- sapply(text.extractNoun, USE.NAMES=F)
noun2 <- unlist(noun)			// 추출된 명사 통합

# 무의미한 단어 제거
noun2 <- noun2[nchar(noun2)>1]		// 1글자 단어 제거
noun2 <- gsub("하지","",noun2)		// '하지' 제거
noun2 <- gsub("때문","",noun2)		// '때문' 제거
wordcount <- table(noun2)		// 단어 빈도수 계산
wordcloud(names(wordcount),
          freq=wordcount,
          scale=c(6,0.7),
          min.freq=3,
          random.order=F,
          rot.per=.1,
          colors=pal2)

# 인터넷 검색어 분석
1. 랭킹으로 트렌드 분석
네이버 데이터 랩과 구글 트렌드가 대표적.
분야별 인기검색어 확인.

2. 관심 키워드로 트렌드 분석

3. 카드지출 추이

# 공공 빅데이터 
1. 공공 빅데이터 포탈에서 서울시에서는 공공데이터를 활용하여 공중화장실의 위치정보를 알 수 있음
2. 기상청 날씨누리
3. 국가 통계포털

# 로지스틱 회귀분석 : 연속형 숫자가 아닌 범주형 값인 경우를 다루기 위해서 만들어진 통계적 방법 
  ex)iris 데이터셋에서 4개의 측정값을 가지고 품종을 예측. 품종이 범주형 값

* 로지스틱 회귀모델 만들기
iris.new <- iris
iris.new$Species <- as.integer(iris.new$Species)	// 범주형 자료를 정수로 변환
head(iris.new)
mod.iris <- glm(Species ~., data= iris.new)		// 로지스틱 회귀모델 도출
summary(mod.iris)					// 회귀모델의 상세 내용 확인


** 구해놓은 회귀모델을 이요하여 보다 편리한 방법으로 품종을 예측해보자. 
# 예측 대상 데이터 생성(데이터프레임)
unknown <- data.frame(rbind(c(5.1,3.5,1.4,0.2)))
names(unknown) <- names(iris)[1:4]
unknown                      

pred <- predict(mod.iris, unknown)		// 품종 예측
pred						
round(pred,0)					// 예측 결과 출력(소수 첫째 자리에서 반올림)

# 실제 품종명 알아보기
pred <- round(pred,0)
pred
levels(iris$Species)
levels(iris$Species)[pred]

# 다수의 데이터에 대한 예측
test <- iris[,1:4]			// 예측 대상 데이터 준비
pred <- predict(mod.iris, test)		// 모델을 이용한 예측
pred <- round(pred,0)
pred
answer <- as.integer(iris$Species)	// 실제 품종 정보
pred == answer				// 예측 품종과 실제 품종이 같은지 비교
acc <- mean(pred ==answer)		// 예측 정확도 계산
acc				

# 업종별 점포수의 변화
store.change <- aggregate(ds.total[,1],
                          by=list(연월=ds.total$수집연월,
                          업종대분류=ds.total$상권업종대분류명),
                          FUN=length)
head(store.change)
names(store.change)[3] <- c("count")
ggplot(store.change, aes(x=연월, y=count, colour=업종대분류, group=업종대분류)) + 
        geom_line() +
        geom_point(size=6, shape=19, alpha=0.5) + 
        ggtitle("업종별 점포수 변화 (대분류")) +
        ylab("점포수") +
        scale_x_continuous(breaks=1:5,
                           labels=files) +
        theme(plot.title = element_text(color="black", size=14, face="bold"))



names(store.dong.201512)[3] <- c("cnt_2015")
store.dong.201712 <- store.tmp[store.tmp$연월==5,]
names(store.dong.201712)[3] <- c("cnt_2017")
store.diff <- merge(store.dong.201512[,2:3], store.dong.201712[,2:3])
store.diff$diff <- abs(store.diff$cnt_2015-store.diff$cnt_2017)
store.diff <- store.diff[order(by=store.diff$diff, decreasing=T),]
top10 <- store.diff[1:10,1]
top10
store.change <- subset(store.tmp, store.tmp$동이름 %in% top10)
ggplot(store.change, aes(x=연월, y=count, colour=동이름, group=동이름))
+
geom_line() +
geom_point(size=6, shape=19, alpha=0.5) + 
ggtitle("점포수 변화 Top 10동") +
ylab("점포수") +
scale_x_continous(breaks=1:5,
	labels=files) +
theme(plot.title = element_text(color="black", size=14, face="bold"))

# 구별 점포수의 변화
store.gu <- aggregate(ds.total[,1],
	by=list(연월=ds.total$수집연월,
		구이름=ds.total$시군구명),
	FUN=length)
names(store.gu)[3] <- c("count")
ggplot(store.gu, aes(x=연월, y=count, colour=구이름, group=구이름)) +
geom_line() +
geom_point(size=6, shape=19, alpha=0.5) +
ggtitle("구별 점푸수 변화(대분류)") + 
ylab("점포수") +
scale_x_continuous(breaks=1:5,
	labels=files) +
theme(plot.title = element_text(color="black", size=14, face="bold"))

# 점포수 변화가 큰 상위 10개 동
store.tmp <- aggregate(ds.total[,1],
	by=list(연월=ds.total$수집연월,
		동이름=ds.total$행정동명),
	FUN=length)
names(store.tmp)[3] <- c("count")
store.dong.201512 <- store.tmp[store.tmp$연월==1,]

ds.yeoksam <- subset(ds.total, ds.total$수집연월==5 &
	ds.total$행정동명=="역삼1동")
# 점포를 업종별로 구분하여 지도에 표시
cen <- c(mean(ds.yeoksam$경도),mean(ds.yeoksam$위도))
map <- get_googlemap(center=cen,
	maptype="roadmap",
	size=c(640,640),
	zoom=15)
gmap <- ggmap(map
gmap + geom_point(data = ds.yeoksam,
	aes(x=경도,y=위도,color=상권업종대분류명),sizee=2,alpha=0.7) +
	labs(x = "Longitude", y = "Latitude",
	title="역삼 1동 업종별 점포", color = "업종")

# 커피 점포만 지도에 표시
ds.yeoksam2 <- subset(ds.yeoksam, ds.yeoksam$상군업종소분류명==
	"커피전문점/카페/다방")
gmap+geom_point(data = ds.yeoksam2,
	aes(x=경도,y=위도), size=2, alpha=0.5, col="red") +
	labs(x = "Longitude"m, y = "Latitude",
		title="역삼1동 커피점")


//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
# 노래가사 자주사용된 단어 빈도
install.packages("rJava")
install.packages("memoise")
install.packages("KoNLP")
library(KoNLP)
library(dplyr)
library(stringr)
library(dplyr)
Sys.setenv(JAVA_HOME='C:/Program Files/Java/jdk1.8.0_221')
useNIADic()
txt <- readLines("hiphop.txt")
head(txt)
install.packages("stringr")
txt <- str_replace_all(txt, "\\W", " ")
txt

extractNoun("대한민국의 영토는 한반도와 그 부속도서로 한다.")
nouns <- extractNoun(txt)
wordcount <- table(unlist(nouns))

df_word <- as.data.frame(wordcount, stringsAsFactors = F)

df_word <- rename(df_word,
                word = Var1,
                freq = Freq)

df_word <- filter(df_word, nchar(word) >= 2)
top_20 <- df_word %>%
        arrange(desc(freq)) %>%
        head(20)

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
library(wordcloud)
library(RColorBrewer)

pal <- brewer.pal(8,"Dark2")			// Dark2 색상 목록에서 8개 색상 추출

set.seed(1234)					// 난수 고정
wordcloud(words = df_word$word$word,		// 단어
          freq = df_word$freq,			// 빈도
          min.freq = 2,				// 최소 단어 빈도
          max.words = 200,			// 표현 단어 수 
          random.order =F,			// 고빈도 단어 중앙 배치
          rot.per = .1,				// 회전 단어 비율
          scale = c(4,0.3),			// 단어 크기 범위
          colors = pal)				// 색깔 목록
          )

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
setwd("C:/source")
# 데이터 로드
twitter <- read.csv("twitter.csv",
                    header = T,
                    stringsAsFactors = F,
                    fileEncoding = "UTF-8")

# 변수명 수정
twitter <- rename(twitter,
                  no = 번호,
                  id = 계정이름,
                  date = 작성일,
                  tw = 내용)

# 특수문자 제거
twitter$tw <- str_replace_all(twitter$tw, "\\W", " ")

# 트윗에서 명사추출
nouns <- extractNoun(twitter$tw)

# 추출한 명사 list를 문자열 벡터로 변환, 단어별 빈도표 생성
wordcount <- table(unlist(nouns))

# 데이터 프레임으로 변환
df_word <- as.data.frame(wordcount, stringsAsFactors = F)

# 변수명 수정
df_word <- rename(df_word,
                  word = Var1,
                  freq = Freq)

# 두글자 이상 단어만 추출
df_word <- filter(df_word, nchar(word) >= 2)

# 상위 20개 추출
top20 <- df_word %>%
        arrange(desc(freq)) %>%
        head(20)

# 워드 클라우드 만들기
pal <- brewer.pal(8, "Dark2")  // pal <- brewer.pal(8, "Blues")[5:9]    //  다른색으로 바꾸기
set.seed(1234)

wordcloud(words = df_word$word,
          freq = df_word$freq,
          min.freq = 10,
          max.words = 200,
          random.order = F,
          rot.per = .1,
          scale = c(6, 0.2),
          colors = pal)

# 미국 주별 강력 범죄율 단계 구분도 만들기
install.packages("ggiraphExtra")
library(ggiraphExtra)

str(USArrests)
head(USArrests)
library(tibble)

# 행 이름을 state 변수로 바꿔 데이터 프레임생성
crime <- rownames_to_column(USArrests, var = "state")

# 지도 데이터와 동일하게 맞추기 위해 state의 값을 소문자로 수정
crime$state <-tolower(crime$state)

# 미국 주 지도 데이터 준비하기
library(ggplot2)
states_map <- map_data("state")
str(states_map)

# 단계 구분도 만들기
ggChoropleth(data=crime,
             aes(fill = Murder,
                 map_id = state),
             map = states_map,
	     interactive = T) 	 	// 인터랙티브

## 대한민국 시도별 인구 단계 구분도 만들기
# 패키지 준비하기
install.packages("stringi")
install.packages("devtools")
devtools::install_github("cardiomoon/kormaps2014")
library(kormaps2014)
str(changeCode(korpop1))

library(dplyr)
korpop1 <- rename(korpop1,
                  pop = 총인구_명,
                  name = 행정구역별_읍면동)
str(changeCode(kormap1))

# 단계 구분도 만들기
library(ggiraphExtra)
library(maps)
library(mapproj)
library(ggplot2)
library(tibble)

ggChoropleth(data = korpop1,
             aes(fill = pop,
                 map_id = code,
                 tooltip = name),
             map = kormap1,
             interactive = T)

str(changeCode(tbc)) // 도별로 조회하기

## plotly 패키지로 인터랙티브 그래프 만들기
# 인터랙티브 그래프 만들기
install.packages("plotly")
library(plotly)
library(ggplot2)

* 점 그래프
p <- ggplot(data = mpg, aes(x = displ, y= hwy, col = drv)) + geom_point()
ggplotly(p)

* 막대 그래프
p <- ggplot(data = diamonds, aes(x = cut, fill = clarity)) +
        geom_bar(position = "dodge")
ggplotly(p)

* 시계열 그래프 만들기
install.packages("dygraphs")
library(dygraphs)
economics <- ggplot2::economics
head(economics)

library(xts)

eco <- xts(economics$unemploy, order.by = economics$date)
dygraph(eco)
head(eco)
dygraph(eco) %>% dyRangeSelector() 	// 날짜에 따른 셀렉터

* 여러 값 표현하기
eco_a <- xts(economics$psavert, order.by = economics$date)		// 저축률
eco_b <- xts(economics$unemploy/1000, order.by = economics$date)	// 실업자 수

* 합치기
eco2 <- cbind(eco_a, eco_b) 			// 데이터 결합
colnames(eco2) <- c("psavert", "unemploy")	// 변수명 바꾸기
head(eco2)

* dygraph(eco2) %>% dyRangeSelector() 		// 비교하기